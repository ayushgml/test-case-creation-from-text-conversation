{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss9Tlo25JSGX"
      },
      "source": [
        "### 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7Cx2h2dJSGa"
      },
      "outputs": [],
      "source": [
        "# for text preprocessing\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "# import vectorizers\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "# import numpy for matrix operation\n",
        "import numpy as np\n",
        "\n",
        "# import LDA from sklearn\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxXUBkBcJSGb"
      },
      "outputs": [],
      "source": [
        "# to suppress warnings\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmPYmWJgJSGb"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import nltk\n",
        "from gensim import corpora\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import WordNetLemmatizer\n",
        "import string"
      ],
      "metadata": {
        "id": "pH6Kl5NxS07B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSSnt3idpt8z",
        "outputId": "486bb629-071e-4df7-cf25-d019596d0e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Preprocessing on the Corpus\n",
        "# stop Loss words\n",
        "doc = open(\"/content/dataset.txt\")\n",
        "doc=doc.read()\n",
        "stop = set (stopwords.words('english'))\n",
        "# punctuation\n",
        "exclude = set(string.punctuation)\n",
        "# Lemmatization\n",
        "lemma = WordNetLemmatizer()\n",
        "corpus = nltk.tokenize.sent_tokenize(doc)\n",
        "print(corpus)\n",
        "# One function for all the steps:\n",
        "def clean(doc):\n",
        "    # convert text into Lower case + split into words\n",
        "    stop_free =\" \".join([i for i in doc.lower ().split() if i not in stop])\n",
        "    # remove any stop words present\n",
        "    punc_free =' '.join(ch for ch in stop_free if ch not in exclude)\n",
        "    # remove punctuations + normalize the text\n",
        "    normalized =\" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
        "    return normalized\n",
        "# clean data stored in a new List\n",
        "# clean_corpus = [clean(doc).split() for doc in corpus]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlC_DeiDS7uC",
        "outputId": "29443218-5a14-4a36-dc72-89c89d6d6464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aerodynamics, from Greek ἀήρ aero (air) + δυναμική (dynamics), is the study of the motion of air, particularly when affected by a solid object, such as an airplane wing.', 'It involves topics covered in the field of fluid dynamics and its subfield of gas dynamics.The term aerodynamics is often used synonymously with gas dynamics, the difference being that \"gas dynamics\" applies to the study of the motion of all gases, and is not limited to air.', 'The formal study of aerodynamics began in the modern sense in the eighteenth century, although observations of fundamental concepts such as aerodynamic drag were recorded much earlier.', 'Most of the early efforts in aerodynamics were directed toward achieving heavier-than-air flight, which was first demonstrated by Otto Lilienthal in 1891.', '[1] Since then, the use of aerodynamics through mathematical analysis, empirical approximations, wind tunnel experimentation, and computer simulations has formed a rational basis for the development of heavier-than-air flight and a number of other technologies.', 'Recent work in aerodynamics has focused on issues related to compressible flow, turbulence, and boundary layers and has become increasingly computational in nature.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNATC-NcaVrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4497fa4-3291-47cc-8b9a-c2d3b1ac5405"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Aerodynamics, from Greek ἀήρ aero (air) + δυναμική (dynamics), is the study of the motion of air, particularly when affected by a solid object, such as an airplane wing.',\n",
              " 'It involves topics covered in the field of fluid dynamics and its subfield of gas dynamics.The term aerodynamics is often used synonymously with gas dynamics, the difference being that \"gas dynamics\" applies to the study of the motion of all gases, and is not limited to air.',\n",
              " 'The formal study of aerodynamics began in the modern sense in the eighteenth century, although observations of fundamental concepts such as aerodynamic drag were recorded much earlier.',\n",
              " 'Most of the early efforts in aerodynamics were directed toward achieving heavier-than-air flight, which was first demonstrated by Otto Lilienthal in 1891.',\n",
              " '[1] Since then, the use of aerodynamics through mathematical analysis, empirical approximations, wind tunnel experimentation, and computer simulations has formed a rational basis for the development of heavier-than-air flight and a number of other technologies.',\n",
              " 'Recent work in aerodynamics has focused on issues related to compressible flow, turbulence, and boundary layers and has become increasingly computational in nature.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# the complete corpus as below:\n",
        "\n",
        "corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYn1CnRvJSGd"
      },
      "source": [
        "### 2. Text Preprocessing\n",
        "\n",
        "Steps to preprocess text data:\n",
        "\n",
        "1. Convert the text into lowercase\n",
        "2. Split text into words\n",
        "3. Remove the stop loss words\n",
        "3. Remove the Punctuation, any symbols and special characters\n",
        "4. Normalize the word (I'll be using Lemmatization for normalization)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg_A2pFgJq7s",
        "outputId": "2e9d9e8c-853d-423c-9df3-7d095b8b5f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7prhxBxWJSGe"
      },
      "outputs": [],
      "source": [
        "# Apply Preprocessing on the Corpus\n",
        "\n",
        "# stop loss words \n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "# punctuation \n",
        "exclude = set(string.punctuation) \n",
        "\n",
        "# lemmatization\n",
        "lemma = WordNetLemmatizer() \n",
        "\n",
        "# One function for all the steps:\n",
        "def clean(doc):\n",
        "    \n",
        "    # convert text into lower case + split into words\n",
        "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
        "    \n",
        "    # remove any stop words present\n",
        "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)  \n",
        "    \n",
        "    # remove punctuations + normalize the text\n",
        "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())  \n",
        "    return normalized\n",
        "\n",
        "# clean data stored in a new list\n",
        "clean_corpus = [clean(doc).split() for doc in corpus]   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p1-TT_hJSGf",
        "outputId": "b585669a-f488-428b-d2d9-6b68463dedda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['aerodynamics',\n",
              "  'greek',\n",
              "  'ἀήρ',\n",
              "  'aero',\n",
              "  'air',\n",
              "  'δυναμική',\n",
              "  'dynamic',\n",
              "  'study',\n",
              "  'motion',\n",
              "  'air',\n",
              "  'particularly',\n",
              "  'affected',\n",
              "  'solid',\n",
              "  'object',\n",
              "  'airplane',\n",
              "  'wing'],\n",
              " ['involves',\n",
              "  'topic',\n",
              "  'covered',\n",
              "  'field',\n",
              "  'fluid',\n",
              "  'dynamic',\n",
              "  'subfield',\n",
              "  'gas',\n",
              "  'dynamicsthe',\n",
              "  'term',\n",
              "  'aerodynamics',\n",
              "  'often',\n",
              "  'used',\n",
              "  'synonymously',\n",
              "  'gas',\n",
              "  'dynamic',\n",
              "  'difference',\n",
              "  'gas',\n",
              "  'dynamic',\n",
              "  'applies',\n",
              "  'study',\n",
              "  'motion',\n",
              "  'gas',\n",
              "  'limited',\n",
              "  'air'],\n",
              " ['formal',\n",
              "  'study',\n",
              "  'aerodynamics',\n",
              "  'began',\n",
              "  'modern',\n",
              "  'sense',\n",
              "  'eighteenth',\n",
              "  'century',\n",
              "  'although',\n",
              "  'observation',\n",
              "  'fundamental',\n",
              "  'concept',\n",
              "  'aerodynamic',\n",
              "  'drag',\n",
              "  'recorded',\n",
              "  'much',\n",
              "  'earlier'],\n",
              " ['early',\n",
              "  'effort',\n",
              "  'aerodynamics',\n",
              "  'directed',\n",
              "  'toward',\n",
              "  'achieving',\n",
              "  'heavierthanair',\n",
              "  'flight',\n",
              "  'first',\n",
              "  'demonstrated',\n",
              "  'otto',\n",
              "  'lilienthal',\n",
              "  '1891'],\n",
              " ['1',\n",
              "  'since',\n",
              "  'then',\n",
              "  'use',\n",
              "  'aerodynamics',\n",
              "  'mathematical',\n",
              "  'analysis',\n",
              "  'empirical',\n",
              "  'approximation',\n",
              "  'wind',\n",
              "  'tunnel',\n",
              "  'experimentation',\n",
              "  'computer',\n",
              "  'simulation',\n",
              "  'formed',\n",
              "  'rational',\n",
              "  'basis',\n",
              "  'development',\n",
              "  'heavierthanair',\n",
              "  'flight',\n",
              "  'number',\n",
              "  'technology'],\n",
              " ['recent',\n",
              "  'work',\n",
              "  'aerodynamics',\n",
              "  'focused',\n",
              "  'issue',\n",
              "  'related',\n",
              "  'compressible',\n",
              "  'flow',\n",
              "  'turbulence',\n",
              "  'boundary',\n",
              "  'layer',\n",
              "  'become',\n",
              "  'increasingly',\n",
              "  'computational',\n",
              "  'nature']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "clean_corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij9gkyz9JSGf"
      },
      "source": [
        "### 3. Convert Text into Numerical Representation\n",
        "\n",
        "Converting the clean preprocessed corpus to array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAZzqUZ0JSGf"
      },
      "outputs": [],
      "source": [
        "# Converting text into numerical representation\n",
        "tf_idf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
        "\n",
        "# Converting text into numerical representation\n",
        "cv_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgjAOvoZaVr0"
      },
      "outputs": [],
      "source": [
        "# Array from TF-IDF Vectorizer \n",
        "tf_idf_arr = tf_idf_vectorizer.fit_transform(clean_corpus)\n",
        "\n",
        "# Array from Count Vectorizer \n",
        "cv_arr = cv_vectorizer.fit_transform(clean_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28mhezCEJSGg",
        "outputId": "04721d76-bd88-477b-a6cd-7b67a8301b12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6x90 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 102 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# this is our converted text to numerical representation from the Tf-IDF vectorizer\n",
        "\n",
        "tf_idf_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCMaicgDJSGg",
        "outputId": "e7e2adbc-7f97-41a2-ac2f-6e8cc1289349"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6x90 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 102 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# this is our converted text to numerical representation from the Count vectorizer\n",
        "cv_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ygFEWCMaVr6",
        "outputId": "599a8c11-aae8-418d-efb6-28ae1080a713"
      },
      "source": [
        "The corpus has 52 columns and 5 rows corresponding to our document and 58 represents the unique Vocabulary present in our corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmdKIbSEaVr_",
        "outputId": "a3572b59-7e0b-4b33-bf09-5a227282639d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1',\n",
              " '1891',\n",
              " 'achieving',\n",
              " 'aero',\n",
              " 'aerodynamic',\n",
              " 'aerodynamics',\n",
              " 'affected',\n",
              " 'air',\n",
              " 'airplane',\n",
              " 'although',\n",
              " 'analysis',\n",
              " 'applies',\n",
              " 'approximation',\n",
              " 'basis',\n",
              " 'become',\n",
              " 'began',\n",
              " 'boundary',\n",
              " 'century',\n",
              " 'compressible',\n",
              " 'computational',\n",
              " 'computer',\n",
              " 'concept',\n",
              " 'covered',\n",
              " 'demonstrated',\n",
              " 'development',\n",
              " 'difference',\n",
              " 'directed',\n",
              " 'drag',\n",
              " 'dynamic',\n",
              " 'dynamicsthe',\n",
              " 'earlier',\n",
              " 'early',\n",
              " 'effort',\n",
              " 'eighteenth',\n",
              " 'empirical',\n",
              " 'experimentation',\n",
              " 'field',\n",
              " 'first',\n",
              " 'flight',\n",
              " 'flow',\n",
              " 'fluid',\n",
              " 'focused',\n",
              " 'formal',\n",
              " 'formed',\n",
              " 'fundamental',\n",
              " 'gas',\n",
              " 'greek',\n",
              " 'heavierthanair',\n",
              " 'increasingly',\n",
              " 'involves',\n",
              " 'issue',\n",
              " 'layer',\n",
              " 'lilienthal',\n",
              " 'limited',\n",
              " 'mathematical',\n",
              " 'modern',\n",
              " 'motion',\n",
              " 'much',\n",
              " 'nature',\n",
              " 'number',\n",
              " 'object',\n",
              " 'observation',\n",
              " 'often',\n",
              " 'otto',\n",
              " 'particularly',\n",
              " 'rational',\n",
              " 'recent',\n",
              " 'recorded',\n",
              " 'related',\n",
              " 'sense',\n",
              " 'simulation',\n",
              " 'since',\n",
              " 'solid',\n",
              " 'study',\n",
              " 'subfield',\n",
              " 'synonymously',\n",
              " 'technology',\n",
              " 'term',\n",
              " 'then',\n",
              " 'topic',\n",
              " 'toward',\n",
              " 'tunnel',\n",
              " 'turbulence',\n",
              " 'use',\n",
              " 'used',\n",
              " 'wind',\n",
              " 'wing',\n",
              " 'work',\n",
              " 'δυναμική',\n",
              " 'ἀήρ']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Creating vocabulary array which will represent all the corpus \n",
        "vocab_tf_idf = tf_idf_vectorizer.get_feature_names()\n",
        "\n",
        "# get the vocb list\n",
        "vocab_tf_idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0b2fe6-b9ac-4e9e-8dc8-dcc02dc5780e",
        "id": "BGAzgCzGJSGh"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1',\n",
              " '1891',\n",
              " 'achieving',\n",
              " 'aero',\n",
              " 'aerodynamic',\n",
              " 'aerodynamics',\n",
              " 'affected',\n",
              " 'air',\n",
              " 'airplane',\n",
              " 'although',\n",
              " 'analysis',\n",
              " 'applies',\n",
              " 'approximation',\n",
              " 'basis',\n",
              " 'become',\n",
              " 'began',\n",
              " 'boundary',\n",
              " 'century',\n",
              " 'compressible',\n",
              " 'computational',\n",
              " 'computer',\n",
              " 'concept',\n",
              " 'covered',\n",
              " 'demonstrated',\n",
              " 'development',\n",
              " 'difference',\n",
              " 'directed',\n",
              " 'drag',\n",
              " 'dynamic',\n",
              " 'dynamicsthe',\n",
              " 'earlier',\n",
              " 'early',\n",
              " 'effort',\n",
              " 'eighteenth',\n",
              " 'empirical',\n",
              " 'experimentation',\n",
              " 'field',\n",
              " 'first',\n",
              " 'flight',\n",
              " 'flow',\n",
              " 'fluid',\n",
              " 'focused',\n",
              " 'formal',\n",
              " 'formed',\n",
              " 'fundamental',\n",
              " 'gas',\n",
              " 'greek',\n",
              " 'heavierthanair',\n",
              " 'increasingly',\n",
              " 'involves',\n",
              " 'issue',\n",
              " 'layer',\n",
              " 'lilienthal',\n",
              " 'limited',\n",
              " 'mathematical',\n",
              " 'modern',\n",
              " 'motion',\n",
              " 'much',\n",
              " 'nature',\n",
              " 'number',\n",
              " 'object',\n",
              " 'observation',\n",
              " 'often',\n",
              " 'otto',\n",
              " 'particularly',\n",
              " 'rational',\n",
              " 'recent',\n",
              " 'recorded',\n",
              " 'related',\n",
              " 'sense',\n",
              " 'simulation',\n",
              " 'since',\n",
              " 'solid',\n",
              " 'study',\n",
              " 'subfield',\n",
              " 'synonymously',\n",
              " 'technology',\n",
              " 'term',\n",
              " 'then',\n",
              " 'topic',\n",
              " 'toward',\n",
              " 'tunnel',\n",
              " 'turbulence',\n",
              " 'use',\n",
              " 'used',\n",
              " 'wind',\n",
              " 'wing',\n",
              " 'work',\n",
              " 'δυναμική',\n",
              " 'ἀήρ']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Creating vocabulary array which will represent all the corpus \n",
        "vocab_cv = cv_vectorizer.get_feature_names()\n",
        "\n",
        "# get the vocb list\n",
        "vocab_cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "L2kK937OJSGh",
        "outputId": "fc8d2bcc-6bf8-4844-ab28-5a81779a1155"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(len(vocab_tf_idf))\n",
        "display(len(vocab_cv))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skLNEW7gJSGh"
      },
      "source": [
        "### 4. Implementation of LDA\n",
        "\n",
        "To implement LDA, pass the corpus: document-term matrix to the model. We had above obtained the unique words of vocabulary using both TF-IDF and Count Vectorizer. We can continue with either as have the same unique words in both the obtained vocabularies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X5BJB_aaVsE"
      },
      "outputs": [],
      "source": [
        " # Implementation of LDA:\n",
        "    \n",
        "# Create object for the LDA class \n",
        "# Inside this class LDA: define the components:\n",
        "lda_model = LatentDirichletAllocation(n_components = 6, max_iter = 20, random_state = 20)\n",
        "\n",
        "# fit transform on model on our count_vectorizer : running this will return our topics \n",
        "X_topics = lda_model.fit_transform(tf_idf_arr)\n",
        "\n",
        "# .components_ gives us our topic distribution \n",
        "topic_words = lda_model.components_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwxZB4CAJSGi"
      },
      "source": [
        "### 4a. Retrieve the Topics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9zZ2_77aVsJ",
        "outputId": "1d278310-c212-45df-8799-92ccee340a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1 ['gas' 'dynamic' 'air' 'study' 'aerodynamics' 'motion']\n",
            "Topic 2 ['aerodynamics' 'heavierthanair' 'flight' 'involves' 'term' 'covered']\n",
            "Topic 3 ['demonstrated' 'toward' 'otto' 'early' 'effort' 'lilienthal']\n",
            "Topic 4 ['aerodynamics' 'heavierthanair' 'flight' 'involves' 'term' 'covered']\n",
            "Topic 5 ['aerodynamics' 'heavierthanair' 'flight' 'involves' 'term' 'covered']\n",
            "Topic 6 ['compressible' 'become' 'flow' 'increasingly' 'issue' 'layer']\n"
          ]
        }
      ],
      "source": [
        "#  Define the number of Words that we want to print in every topic : n_top_words\n",
        "n_top_words = 7\n",
        "\n",
        "for i, topic_dist in enumerate(topic_words):\n",
        "    \n",
        "    # np.argsort to sorting an array or a list or the matrix acc to their values\n",
        "    sorted_topic_dist = np.argsort(topic_dist)\n",
        "    \n",
        "    # Next, to view the actual words present in those indexes we can make the use of the vocab created earlier\n",
        "    topic_words = np.array(vocab_tf_idf)[sorted_topic_dist]\n",
        "    \n",
        "    # so using the sorted_topic_indexes we ar extracting the words from the vocabulary\n",
        "    # obtaining topics + words\n",
        "    # this topic_words variable contains the Topics  as well as the respective words present in those Topics\n",
        "    topic_words = topic_words[:-n_top_words:-1]\n",
        "    print (\"Topic\", str(i+1), topic_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLNJvU0sJSGi"
      },
      "source": [
        "Above is the words per topic. The result is not so accurate as the data was less. More data will give more accurate result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHk1rGKPJSGi"
      },
      "source": [
        "### 4b. Annotating the topics the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s31RUYKaVsQ",
        "outputId": "eeb6ad29-9bd2-4459-ea96-501e0f049ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1  -- Topic: 0\n",
            "Document 2  -- Topic: 0\n",
            "Document 3  -- Topic: 0\n",
            "Document 4  -- Topic: 2\n",
            "Document 5  -- Topic: 0\n",
            "Document 6  -- Topic: 5\n"
          ]
        }
      ],
      "source": [
        "# To view what topics are assigned to the douments:\n",
        "\n",
        "doc_topic = lda_model.transform(tf_idf_arr)  \n",
        "\n",
        "# iterating over ever value till the end value\n",
        "for n in range(doc_topic.shape[0]):\n",
        "    \n",
        "    # argmax() gives maximum index value\n",
        "    topic_doc = doc_topic[n].argmax()\n",
        "    \n",
        "    # document is n+1  \n",
        "    print (\"Document\", n+1, \" -- Topic:\" ,topic_doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noULy6qnJSGj"
      },
      "source": [
        "This is the final output which gives us the topic along with the documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "holU5L09JSGj"
      },
      "source": [
        "-----------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import http.client\n",
        "s1 = \"['\"\n",
        "s1 = s1 + \"',_'\".join(vocab_cv)\n",
        "s1 = s1 + \"]\"\n",
        "conn = http.client.HTTPSConnection(\"google-search3.p.rapidapi.com\")\n",
        "\n",
        "headers = {\n",
        "    'X-User-Agent': \"desktop\",\n",
        "    'X-Proxy-Location': \"EU\",\n",
        "    'X-RapidAPI-Host': \"google-search3.p.rapidapi.com\",\n",
        "    'X-RapidAPI-Key': \"f62bd26370msh21382210477831cp122bfcjsn463c8f5cc60a\"\n",
        "    }\n",
        "\n",
        "conn.request(\"GET\", \"/api/v1/search/q=\"+s1, headers=headers)\n",
        "\n",
        "res = conn.getresponse()\n",
        "data = res.read()\n",
        "answer1 = data.decode(\"utf-8\")\n",
        "print(answer1)"
      ],
      "metadata": {
        "id": "BnFQjmWVKRJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a48f63-7ca2-453f-f693-c1c126e1a079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"results\":[{\"title\":\"Ethernet Interface Module Hardware and Common Platform ...\",\"link\":\"https://process.honeywell.com/bin/edam/getfileservlet?id=06IqFSggTa5PDWj/9KcMuVmZlUorFshGoC2cHPkRgZU3mCnQmKd9/xp0+481QqJiIiu7vFc471vfTyuoB4fqInawyyZc/yEj8QrPH0yQbxFVKbMcM7u1JMV+c5NWPtKGJr/m/bXgCbnwW44kCXD2EuYetekhXceaDBP/e6PFZTnwzVsayXn8PPrK0llgWpak0Zy8+RoXXAZdGXBEU6JgLcbC75APgH1mS58oEXuMATjq1R0lUD0wteI05Uk3vPl7Ar3SNmKY2zPWc06BPp/EbEVoH9coCd1IF0V7lFLGsQbmdYSY3EzBxgxsGUU2uuq/+Hv1LeHH89jWz2RQfEBOtdCaU+o1YgT1hNo0Tdfph0s2rmD/drMdS4e5B3A=\",\"description\":\"7.1 EIM Module Configuration Rules. 35. 7.2 Creating an EIM block in Control Builder. 36. 7.2.1 Prerequisites. 37. 7.2.2 Create and configure nonredundant ...\",\"additional_links\":[{\"text\":\"Ethernet Interface Module Hardware and Common Platform ...https://process.honeywell.com › bin › getfileservlet\",\"href\":\"https://process.honeywell.com/bin/edam/getfileservlet?id=06IqFSggTa5PDWj/9KcMuVmZlUorFshGoC2cHPkRgZU3mCnQmKd9/xp0+481QqJiIiu7vFc471vfTyuoB4fqInawyyZc/yEj8QrPH0yQbxFVKbMcM7u1JMV+c5NWPtKGJr/m/bXgCbnwW44kCXD2EuYetekhXceaDBP/e6PFZTnwzVsayXn8PPrK0llgWpak0Zy8+RoXXAZdGXBEU6JgLcbC75APgH1mS58oEXuMATjq1R0lUD0wteI05Uk3vPl7Ar3SNmKY2zPWc06BPp/EbEVoH9coCd1IF0V7lFLGsQbmdYSY3EzBxgxsGUU2uuq/+Hv1LeHH89jWz2RQfEBOtdCaU+o1YgT1hNo0Tdfph0s2rmD/drMdS4e5B3A=\"}],\"cite\":{\"domain\":\"https://process.honeywell.com › bin › getfileservlet\",\"span\":\" › bin › getfileservlet\"}},{\"title\":\"19930007131.pdf - NASA Technical Reports Server\",\"link\":\"https://ntrs.nasa.gov/api/citations/19930007131/downloads/19930007131.pdf\",\"description\":\"by B Kobler · 1992 — Next, an ove_'iew of the EMASS architecture is presented and evaluated with respect to NASA's requirements. The major EMASS architectural components,.\",\"additional_links\":[{\"text\":\"19930007131.pdf - NASA Technical Reports Serverhttps://ntrs.nasa.gov › api › citations › downloads\",\"href\":\"https://ntrs.nasa.gov/api/citations/19930007131/downloads/19930007131.pdf\"}],\"cite\":{\"domain\":\"https://ntrs.nasa.gov › api › citations › downloads\",\"span\":\" › api › citations › downloads\"}},{\"title\":\"DTIC FILE COPy\",\"link\":\"https://apps.dtic.mil/sti/pdfs/ADA221474.pdf\",\"description\":\" › sti › pdfs › ADA221474  › sti › pdfs › ADA221474 PDF by FA Tobagi · 1984 —  by FA Tobagi  ·  1984\",\"additional_links\":[{\"text\":\"DTIC FILE COPyhttps://apps.dtic.mil › sti › pdfs › ADA221474\",\"href\":\"https://apps.dtic.mil/sti/pdfs/ADA221474.pdf\"},{\"text\":\"22nd Annual Precise - DTIChttps://apps.dtic.mil › sti › pdfs › ADA239372\",\"href\":\"https://apps.dtic.mil/sti/pdfs/ADA239372.pdf\"}],\"cite\":{\"domain\":\"https://apps.dtic.mil › sti › pdfs › ADA221474\",\"span\":\" › sti › pdfs › ADA221474\"}}],\"image_results\":[],\"total\":4,\"answers\":[],\"ts\":2.1832592487335205,\"device_region\":\"EU\",\"device_type\":\"desktop\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "my_json = json.loads(answer1)\n",
        "my_json"
      ],
      "metadata": {
        "id": "tEl2_zQ5j_jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        " \n",
        " \n",
        "# Opening JSON file and loading the data\n",
        "# into the variable data\n",
        "with open('/content/answers.json','w') as json_file:\n",
        "    json_file.write(answer1)\n",
        " \n",
        "results = my_json['results']\n",
        " \n",
        "# now we will open a file for writing\n",
        "data_file = open('data_file.csv', 'w')\n",
        " \n",
        "# create the csv writer object\n",
        "csv_writer = csv.writer(data_file)\n",
        " \n",
        "# Counter variable used for writing\n",
        "# headers to the CSV file\n",
        "count = 0\n",
        " \n",
        "for resu in results:\n",
        "    if count == 0:\n",
        " \n",
        "        # Writing headers of CSV file\n",
        "        header = resu.keys()\n",
        "        csv_writer.writerow(header)\n",
        "        count += 1\n",
        " \n",
        "    # Writing data of CSV file\n",
        "    csv_writer.writerow(resu.values())\n",
        " \n",
        "data_file.close()"
      ],
      "metadata": {
        "id": "wHIjVVdfnQEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XC3FE5tJyLFg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Copy of 3. Interpreting Patterns from Text - Topic Modelling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}